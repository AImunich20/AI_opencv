openvino_camera.py comment

import cv2
from ultralytics import YOLO
import time
import ipywidgets as widgets
import openvino.runtime as ov

# Initialize OpenVINO Core
model =  YOLO('yolov8n.pt')
model.export(format='openvino',dynamic=True,imgsz=(640,640),half=False)

core = ov.Core()

device = widgets.Dropdown(
    options=core.available_devices + ["GPU"],
    value='GPU',
    description='Device:',
    disabled=False,
)
device

# Load OpenVINO YOLOv8 model
ov_model = YOLO('yolov8n_openvino_model')

# Video source (0 for webcam or provide video file path)
cap = cv2.VideoCapture(0)

while cap.isOpened():
    success, frame = cap.read()
    # Measure inference time
    start_time = time.time()
    results = ov_model(frame)
    end_time = time.time()

    print(f"Inference time: {end_time - start_time:.3f} seconds")

    # Annotate frame
    annotated_frame = results[0].plot()

    # Display the results
    cv2.imshow("YOLOv8 Inference", annotated_frame)

    # Exit on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord("q"):
        print("Exiting...")
        break
        
# Release resources
cap.release()
cv2.destroyAllWindows()
print("Resources released. Program terminated.")

openvino_video.py comment

import cv2
from ultralytics import YOLO
import time
import ipywidgets as widgets
import openvino.runtime as ov

# Load the YOLO model
model = YOLO('yolov8n.pt')  # Optional: Uncomment to load the original PyTorch model
# Export to OpenVINO format (optional, uncomment if needed)
# model.export(format='openvino', dynamic=True, imgsz=(640, 640), half=False)

# Load the exported OpenVINO model
ov_model = YOLO('yolov8n_openvino_model')

# Initialize OpenVINO core and select a device
core = ov.Core()
device = widgets.Dropdown(
    options=core.available_devices + ["GPU"],
    value='GPU',
    description='Device:',
    disabled=False,
)
device

# Load the video file
video_path = 'your_video_file.mp4'  # Replace with the path to your video file
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file {video_path}")
    exit()

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        print("End of video or error reading frame.")
        break

    # Perform inference
    start_time = time.time()
    results = ov_model(frame)
    end_time = time.time()
    print(f"Inference time: {end_time - start_time:.3f} seconds")

    # Annotate the frame with detection results
    annotated_frame = results[0].plot()

    # Display the frame
    cv2.imshow("YOLOv8 Inference", annotated_frame)

    # Exit when 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()

openvino_picture.py comment

import cv2
from ultralytics import YOLO
import openvino.runtime as ov

# Load the YOLO model
model = YOLO('yolov8n.pt')  # Optional: Uncomment to load the original PyTorch model
# Export to OpenVINO format (optional, uncomment if needed)
# model.export(format='openvino', dynamic=True, imgsz=(640, 640), half=False)

# Load the exported OpenVINO model
ov_model = YOLO('yolov8n_openvino_model')

# Path to the input image
image_path = 'your_image_file.jpg'  # Replace with the path to your image file

# Read the image
image = cv2.imread(image_path)

if image is None:
    print(f"Error: Could not read image file {image_path}")
    exit()

# Perform inference
results = ov_model(image)

# Annotate the image with detection results
annotated_image = results[0].plot()

# Display the annotated image
cv2.imshow("YOLOv8 Inference", annotated_image)

# Wait for a key press and close the window
cv2.waitKey(0)
cv2.destroyAllWindows()
